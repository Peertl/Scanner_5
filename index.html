<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>AR Measure Pro</title>
<script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvReady();"></script>
<style>
    body { margin: 0; background: #111; color: #fff; font-family: sans-serif; overflow: hidden; }
    
    video, canvas { 
        position: absolute; top: 0; left: 0; 
        width: 100vw; height: 100vh; 
        object-fit: cover; 
    }

    #ui {
        position: absolute; top: 20px; left: 50%; transform: translateX(-50%);
        width: 90%; max-width: 400px; z-index: 10;
        background: rgba(0, 0, 0, .85); padding: 15px;
        border-radius: 12px; backdrop-filter: blur(5px);
        box-shadow: 0 4px 15px rgba(0,0,0,0.5);
        text-align: center;
        transition: opacity 0.3s;
    }

    h2 { margin: 0 0 5px 0; font-size: 1.1rem; color: #00ff88; }
    p { margin: 0; font-size: 0.85rem; color: #ddd; line-height: 1.4; }

    /* Fortschrittsbalken Container */
    .progress-track {
        width: 100%; height: 8px; background: #333;
        margin-top: 10px; border-radius: 4px; overflow: hidden;
    }
    /* Der eigentliche Balken */
    .progress-fill {
        height: 100%; background: #00ff88; width: 0%;
        transition: width 0.3s ease-out;
    }

    /* Lade-Overlay (Spinner) */
    #loading-overlay {
        position: absolute; top: 0; left: 0; width: 100vw; height: 100vh;
        background: rgba(0,0,0,0.8); z-index: 20;
        display: none; flex-direction: column;
        align-items: center; justify-content: center;
    }
    .spinner {
        width: 50px; height: 50px;
        border: 5px solid rgba(255,255,255,0.3);
        border-radius: 50%; border-top-color: #00ff88;
        animation: spin 1s ease-in-out infinite;
        margin-bottom: 15px;
    }
    @keyframes spin { to { transform: rotate(360deg); } }
    
    #result-toast {
        position: absolute; bottom: 30px; left: 50%; transform: translateX(-50%);
        background: rgba(0,255,136, 0.9); color: #000;
        padding: 10px 20px; border-radius: 20px; font-weight: bold;
        z-index: 10; opacity: 0; transition: opacity 0.3s; pointer-events: none;
    }
</style>
</head>
<body>

<video id="video" playsinline muted autoplay></video>
<canvas id="canvas"></canvas>

<!-- UI Panel oben -->
<div id="ui">
    <h2 id="status">Systemstart...</h2>
    <p id="instruction">OpenCV wird geladen</p>
    <div class="progress-track" id="progress-track" style="display:none">
        <div class="progress-fill" id="progress-fill"></div>
    </div>
</div>

<!-- Lade Screen -->
<div id="loading-overlay">
    <div class="spinner"></div>
    <div style="color:#fff; font-weight:bold;">Berechne Kalibrierung...</div>
    <div style="color:#aaa; font-size:0.8rem;">Bitte kurz warten (kann hängen)</div>
</div>

<!-- Ergebnis Toast unten -->
<div id="result-toast">Pos: 0, 0</div>

<script>
// --- Konfiguration ---
const A4_W = 21.0; 
const A4_H = 29.7; 
const FRAMES_NEEDED = 10; // Reduziert von 15 auf 10 für mehr Speed

let video, canvas, ctx;
let streamWidth, streamHeight;

// Kalibrierung
let objPointsCalib, imgPointsCalib;
let cameraMatrix, distCoeffs;
let isCalibrated = false;
let framesCaptured = 0;

// Tracking
let rvec, tvec;
let cvReady = false;

function onOpenCvReady() {
    cvReady = true;
    document.getElementById("status").innerText = "Kamerazugriff";
    document.getElementById("instruction").innerText = "Bitte Zugriff erlauben";
    startCamera();
}

function startCamera() {
    video = document.getElementById("video");
    canvas = document.getElementById("canvas");
    ctx = canvas.getContext("2d");

    // HD reicht völlig, 4K macht es langsam
    const constraints = {
        audio: false,
        video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } }
    };

    navigator.mediaDevices.getUserMedia(constraints).then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
            streamWidth = video.videoWidth;
            streamHeight = video.videoHeight;
            canvas.width = streamWidth;
            canvas.height = streamHeight;
            
            initOpenCV();
            requestAnimationFrame(loop);
        };
    }).catch(err => {
        alert("Fehler: " + err.message);
    });
}

function initOpenCV() {
    objPointsCalib = new cv.MatVector();
    imgPointsCalib = new cv.MatVector();
    
    document.getElementById("status").innerText = "Kalibrierung";
    document.getElementById("instruction").innerText = "Zeige ein A4 Blatt komplett.\nBewege es langsam (Winkel ändern).";
    document.getElementById("progress-track").style.display = "block";
}

function loop() {
    if (!cvReady || !streamWidth) return;

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    let src = cv.imread(canvas);
    
    // Performance: Bild für Erkennung verkleinern (Scale Down 50% wenn sehr groß)
    // Wir lassen es hier erst mal 1:1, da wir 720p angefordert haben, das schafft JS meist gut.
    
    try {
        if (!isCalibrated) {
            findMarkerAndCalibrate(src);
        } else {
            findMarkerAndPose(src);
        }
    } catch (e) {
        console.error(e);
    } finally {
        src.delete(); 
    }

    // Wenn nicht gerade schwer gerechnet wird, weiter loopen
    if(!isCalculating) requestAnimationFrame(loop);
}

// Flag um Loop zu pausieren während Berechnung
let isCalculating = false;

function findMarkerAndCalibrate(src) {
    let result = detectQuad(src);
    
    if (result) {
        let approx = result.approx;
        let corners = sortCorners(approx);
        
        drawQuad(corners, "orange"); // Orange = Kalibrierungsmodus

        // Bedingungen: Blatt groß genug, Random Sample um Frames zu verteilen
        if (framesCaptured < FRAMES_NEEDED && Math.random() > 0.8) {
            
            let obj = cv.matFromArray(4, 1, cv.CV_32FC3, [
                0, 0, 0,       
                A4_W, 0, 0,    
                A4_W, A4_H, 0, 
                0, A4_H, 0     
            ]);
            
            let img = cv.matFromArray(4, 1, cv.CV_32FC2, corners);

            objPointsCalib.push_back(obj);
            imgPointsCalib.push_back(img);
            
            framesCaptured++;
            
            // UI Update
            let percent = (framesCaptured / FRAMES_NEEDED) * 100;
            document.getElementById("progress-fill").style.width = percent + "%";
            document.getElementById("instruction").innerText = `Sammle Daten: ${framesCaptured}/${FRAMES_NEEDED}`;

            obj.delete(); img.delete();
        }
        approx.delete();
    }

    // Wenn fertig, Kalibrierung starten
    if (framesCaptured >= FRAMES_NEEDED && !isCalculating) {
        isCalculating = true; // Loop stoppen
        startCalibrationAsync();
    }
}

function startCalibrationAsync() {
    // 1. UI Overlay anzeigen
    document.getElementById("loading-overlay").style.display = "flex";
    
    // 2. Timeout nutzen, damit der Browser Zeit hat, das Overlay zu rendern (Paint Frame)
    // bevor der Main-Thread von OpenCV blockiert wird.
    setTimeout(() => {
        runCalibration();
    }, 100);
}

function runCalibration() {
    try {
        cameraMatrix = new cv.Mat();
        distCoeffs = new cv.Mat();
        let rvecs = new cv.MatVector();
        let tvecs = new cv.MatVector();
        
        let size = new cv.Size(streamWidth, streamHeight);
        
        // --- DER BLOCKIERENDE TEIL ---
        cv.calibrateCamera(objPointsCalib, imgPointsCalib, size, cameraMatrix, distCoeffs, rvecs, tvecs);
        // -----------------------------

        isCalibrated = true;
        
        // Aufräumen
        objPointsCalib.delete(); imgPointsCalib.delete();
        rvecs.delete(); tvecs.delete();

        // UI Updates
        document.getElementById("status").innerText = "Mess-Modus Aktiv";
        document.getElementById("instruction").innerText = "Tippe auf den Bildschirm zum Messen.";
        document.getElementById("progress-track").style.display = "none";
        
    } catch(e) {
        alert("Kalibrierung fehlgeschlagen. Seite neu laden.");
        console.error(e);
    } finally {
        document.getElementById("loading-overlay").style.display = "none";
        isCalculating = false;
        requestAnimationFrame(loop); // Loop wieder starten
    }
}

function findMarkerAndPose(src) {
    let result = detectQuad(src);
    
    if (result) {
        let approx = result.approx;
        let corners = sortCorners(approx);
        
        drawQuad(corners, "#00ff88"); // Grün = Tracking OK
        
        let imgPts = cv.matFromArray(4, 1, cv.CV_32FC2, corners);
        let objPts = cv.matFromArray(4, 1, cv.CV_32FC3, [
            0, 0, 0, A4_W, 0, 0, A4_W, A4_H, 0, 0, A4_H, 0
        ]);

        if (!rvec) rvec = new cv.Mat();
        if (!tvec) tvec = new cv.Mat();

        cv.solvePnP(objPts, imgPts, cameraMatrix, distCoeffs, rvec, tvec);
        
        imgPts.delete(); objPts.delete(); approx.delete();
    }
}

function detectQuad(src) {
    let gray = new cv.Mat();
    let blur = new cv.Mat();
    let edges = new cv.Mat();
    let contours = new cv.MatVector();
    let hierarchy = new cv.Mat();
    let bestResult = null;

    try {
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        // Leichteres Blur ist schneller
        cv.GaussianBlur(gray, blur, new cv.Size(3, 3), 0);
        cv.Canny(blur, edges, 50, 150);
        
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let maxArea = 0;
        for (let i = 0; i < contours.size(); i++) {
            let cnt = contours.get(i);
            let area = cv.contourArea(cnt);
            
            if (area > 10000) { // Muss groß genug sein
                let peri = cv.arcLength(cnt, true);
                let approx = new cv.Mat();
                cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
                
                if (approx.rows === 4) {
                    if (area > maxArea) {
                        maxArea = area;
                        if (bestResult) bestResult.approx.delete();
                        bestResult = { approx: approx };
                    } else {
                        approx.delete();
                    }
                } else {
                    approx.delete();
                }
            }
        }
    } finally {
        gray.delete(); blur.delete(); edges.delete(); contours.delete(); hierarchy.delete();
    }
    return bestResult;
}

function sortCorners(approx) {
    let d = approx.data32S;
    let pts = [
        {x: d[0], y: d[1]}, {x: d[2], y: d[3]},
        {x: d[4], y: d[5]}, {x: d[6], y: d[7]}
    ];
    pts.sort((a,b) => a.y - b.y);
    let top = pts.slice(0,2).sort((a,b) => a.x - b.x);
    let bottom = pts.slice(2,4).sort((a,b) => a.x - b.x);
    return [top[0].x, top[0].y, top[1].x, top[1].y, bottom[1].x, bottom[1].y, bottom[0].x, bottom[0].y];
}

function drawQuad(coords, color) {
    ctx.strokeStyle = color;
    ctx.lineWidth = 4;
    ctx.lineJoin = "round";
    ctx.beginPath();
    ctx.moveTo(coords[0], coords[1]);
    ctx.lineTo(coords[2], coords[3]);
    ctx.lineTo(coords[4], coords[5]);
    ctx.lineTo(coords[6], coords[7]);
    ctx.closePath();
    ctx.stroke();
}

// --- Interaktion ---
canvas.addEventListener("mousedown", (e) => {
    if (!isCalibrated || !rvec) return;
    
    let rect = canvas.getBoundingClientRect();
    
    // Scaling berechnen (Contain vs Cover vs interne Auflösung)
    let vidRatio = streamWidth / streamHeight;
    let screenRatio = rect.width / rect.height;
    let scale, renderW, renderH, offsetX, offsetY;

    if (screenRatio > vidRatio) {
        scale = rect.width / streamWidth;
    } else {
        scale = rect.height / streamHeight;
    }

    renderW = streamWidth * scale;
    renderH = streamHeight * scale;
    offsetX = (rect.width - renderW) / 2;
    offsetY = (rect.height - renderH) / 2;

    let clickX = (e.clientX - rect.left - offsetX) / scale;
    let clickY = (e.clientY - rect.top - offsetY) / scale;

    if (clickX < 0 || clickX > streamWidth || clickY < 0 || clickY > streamHeight) return;

    let pt = calculateWorldPoint(clickX, clickY);
    
    if (pt) {
        showToast(`X: ${pt.x.toFixed(1)} cm | Y: ${pt.y.toFixed(1)} cm`);
        drawPoint(clickX, clickY);
    }
});

function showToast(text) {
    let t = document.getElementById("result-toast");
    t.innerText = text;
    t.style.opacity = "1";
    setTimeout(() => { t.style.opacity = "0"; }, 3000);
}

function drawPoint(x, y) {
    ctx.fillStyle = "#00ff88";
    ctx.beginPath();
    ctx.arc(x, y, 10, 0, 2*Math.PI);
    ctx.fill();
}

function calculateWorldPoint(u, v) {
    // Ray-Plane Intersection Z=0
    let Kinv = cameraMatrix.inv();
    let R = new cv.Mat(); cv.Rodrigues(rvec, R);
    let Rinv = R.inv();
    
    let uvPoint = cv.matFromArray(3, 1, cv.CV_64F, [u, v, 1]);
    let rayCam = new cv.Mat(); cv.gemm(Kinv, uvPoint, 1, new cv.Mat(), 0, rayCam);
    let rayWorld = new cv.Mat(); cv.gemm(Rinv, rayCam, 1, new cv.Mat(), 0, rayWorld);
    
    let camPos = new cv.Mat();
    cv.gemm(Rinv, tvec, -1, new cv.Mat(), 0, camPos);

    let rZ = rayWorld.data64F[2];
    let cZ = camPos.data64F[2];
    
    if (Math.abs(rZ) < 0.0001) return null;
    
    let s = -cZ / rZ;
    let pX = camPos.data64F[0] + s * rayWorld.data64F[0];
    let pY = camPos.data64F[1] + s * rayWorld.data64F[1];
    
    uvPoint.delete(); rayCam.delete(); rayWorld.delete(); camPos.delete(); Kinv.delete(); R.delete(); Rinv.delete();
    
    return { x: pX, y: pY };
}
</script>
</body>
</html>